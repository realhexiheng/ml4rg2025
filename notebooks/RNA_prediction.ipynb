{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "765c910d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-15 15:27:54--  http://sgd-archive.yeastgenome.org/sequence/S288C_reference/genome_releases/S288C_reference_genome_R64-5-1_20240529.tgz\n",
      "Resolving sgd-archive.yeastgenome.org (sgd-archive.yeastgenome.org)... 52.218.222.18, 52.92.154.75, 52.92.235.35, ...\n",
      "Connecting to sgd-archive.yeastgenome.org (sgd-archive.yeastgenome.org)|52.218.222.18|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20979823 (20M) [application/gzip]\n",
      "Saving to: ‚ÄòS288C_reference_genome_R64-5-1_20240529.tgz‚Äô\n",
      "\n",
      "S288C_reference_gen 100%[===================>]  20.01M  7.00MB/s    in 2.9s    \n",
      "\n",
      "2025-06-15 15:27:57 (7.00 MB/s) - ‚ÄòS288C_reference_genome_R64-5-1_20240529.tgz‚Äô saved [20979823/20979823]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget http://sgd-archive.yeastgenome.org/sequence/S288C_reference/genome_releases/S288C_reference_genome_R64-5-1_20240529.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d92de4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "._S288C_reference_genome_R64-5-1_20240529\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "S288C_reference_genome_R64-5-1_20240529/\n",
      "S288C_reference_genome_R64-5-1_20240529/._rna_coding_R64-5-1_20240529.fasta.gz\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "S288C_reference_genome_R64-5-1_20240529/rna_coding_R64-5-1_20240529.fasta.gz\n",
      "S288C_reference_genome_R64-5-1_20240529/S288C_reference_sequence_R64-5-1_20240529.fsa.gz\n",
      "S288C_reference_genome_R64-5-1_20240529/._NotFeature_R64-5-1_20240529.fasta.gz\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "S288C_reference_genome_R64-5-1_20240529/NotFeature_R64-5-1_20240529.fasta.gz\n",
      "S288C_reference_genome_R64-5-1_20240529/._orf_trans_all_R64-5-1_20240529.fasta.gz\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "S288C_reference_genome_R64-5-1_20240529/orf_trans_all_R64-5-1_20240529.fasta.gz\n",
      "S288C_reference_genome_R64-5-1_20240529/._other_features_genomic_R64-5-1_20240529.fasta.gz\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "S288C_reference_genome_R64-5-1_20240529/other_features_genomic_R64-5-1_20240529.fasta.gz\n",
      "S288C_reference_genome_R64-5-1_20240529/._gene_association_R64-5-1_20240529.sgd\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "S288C_reference_genome_R64-5-1_20240529/gene_association_R64-5-1_20240529.sgd\n",
      "S288C_reference_genome_R64-5-1_20240529/._orf_coding_all_R64-5-1_20240529.fasta.gz\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "S288C_reference_genome_R64-5-1_20240529/orf_coding_all_R64-5-1_20240529.fasta.gz\n",
      "S288C_reference_genome_R64-5-1_20240529/._saccharomyces_cerevisiae_R64-5-1_20240529.gff.gz\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
      "S288C_reference_genome_R64-5-1_20240529/saccharomyces_cerevisiae_R64-5-1_20240529.gff.gz\n"
     ]
    }
   ],
   "source": [
    "! tar -xvzf S288C_reference_genome_R64-5-1_20240529.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230ae992",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -dkf S288C_reference_genome_R64-5-1_20240529/S288C_reference_sequence_R64-5-1_20240529.fsa.gz\n",
    "!mv S288C_reference_genome_R64-5-1_20240529/S288C_reference_sequence_R64-5-1_20240529.fsa fasta_file.fsa\n",
    "!gzip -dkf S288C_reference_genome_R64-5-1_20240529/saccharomyces_cerevisiae_R64-5-1_20240529.gff.gz\n",
    "!mv S288C_reference_genome_R64-5-1_20240529/saccharomyces_cerevisiae_R64-5-1_20240529.gff gff_file.gff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec60047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    BertConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorWithPadding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e668ed2",
   "metadata": {},
   "source": [
    "# Understanding SpeciesLM Model Types\n",
    "\n",
    "**SpeciesLM** offers two types of models with different training focuses:\n",
    "\n",
    "## üß¨ **Upstream Models** (`species_upstream_1000_k1`)\n",
    "- **Training Data**: 1000bp upstream regions of genes (5' regulatory regions)\n",
    "- **Focus**: Promoters, enhancers, transcription factor binding sites\n",
    "- **Best For**: \n",
    "  - Gene expression prediction ‚≠ê (Our use case)\n",
    "  - Transcriptional regulation analysis\n",
    "  - Promoter identification\n",
    "  - Enhancer/silencer detection\n",
    "\n",
    "## üß¨ **Downstream Models** (`downstream_species_lm`)  \n",
    "- **Training Data**: Downstream regions of genes (3' regulatory regions)\n",
    "- **Focus**: Terminators, polyadenylation signals, 3' UTR elements\n",
    "- **Best For**:\n",
    "  - mRNA stability prediction\n",
    "  - Post-transcriptional regulation\n",
    "  - Termination signal identification\n",
    "  - microRNA binding site analysis\n",
    "\n",
    "## üìä **For RNA Expression Prediction**\n",
    "We use the **upstream model** because gene expression is primarily controlled by upstream regulatory elements like promoters and enhancers that initiate transcription.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033529da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sequences(\n",
    "    ds,\n",
    "    tokenizer,\n",
    "    proxy_species,\n",
    "    seq_col=\"five_prime_seq\",\n",
    "    num_proc=16,\n",
    "):\n",
    "    # Tokenize the existing sequences without adding masked versions\n",
    "    def tokenize(example):\n",
    "        return tokenizer(proxy_species + \" \" + \" \".join(example[seq_col]))\n",
    "\n",
    "    hf_ds = Dataset.from_pandas(ds)\n",
    "    tok_ds = hf_ds.map(tokenize, num_proc=num_proc)\n",
    "    tok_ds = tok_ds.flatten_indices()\n",
    "\n",
    "    return tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNALMReconstructor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path=\"/s/project/denovo-prosit/JohannesHingerl/BERTADN/final_models/species_upstream_1000_k1/\",\n",
    "        tokenizer_path=None,\n",
    "        proxy_species=\"kazachstania_africana_cbs_2517_gca_000304475\",\n",
    "        use_hooks=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the DNALMReconstructor with a pre-trained language model.\n",
    "        :param model_path: Path to the pre-trained model.\n",
    "        \"\"\"\n",
    "        tokenizer_path = tokenizer_path = (\n",
    "            tokenizer_path if tokenizer_path else model_path\n",
    "        )\n",
    "        self.model_path = model_path\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        self.config = BertConfig.from_pretrained(model_path)\n",
    "        self.model = AutoModelForMaskedLM.from_pretrained(\n",
    "            self.model_path, config=self.config\n",
    "        )\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        self.nuc_idx = [self.tokenizer.encode(nuc)[1] for nuc in [\"A\", \"C\", \"G\", \"T\"]]\n",
    "        self.proxy_species = proxy_species\n",
    "        self.activation = None\n",
    "\n",
    "    def get_vectors_for_each_nucleotide(\n",
    "        self,\n",
    "        sequence: str,\n",
    "        window_size: int = 1000,\n",
    "        stride: int = 200,\n",
    "        num_proc: int = 16,\n",
    "        batch_size: int = 64,\n",
    "        layers_from: int = 8,\n",
    "    ):\n",
    "        \"Returns a np.array of len(seq), emb_dim vectors\"\n",
    "        embedding_dim = self.config.hidden_size\n",
    "        print(f\"Embedding dimension: {embedding_dim}\")\n",
    "        seq_len = len(sequence)\n",
    "\n",
    "        sum_embeddings = torch.zeros(\n",
    "            (seq_len, embedding_dim), dtype=torch.float32, device=self.device\n",
    "        )\n",
    "        count_embeddings = torch.zeros(seq_len, dtype=torch.float32, device=self.device)\n",
    "\n",
    "        # Prepare start positions list for overlapping windows\n",
    "        sequences = []\n",
    "        start_positions = []\n",
    "        for start_pos in range(0, seq_len, stride):\n",
    "            end_pos = start_pos + window_size\n",
    "            if end_pos > seq_len:\n",
    "                start_pos = seq_len - window_size\n",
    "                end_pos = seq_len\n",
    "            current_chunk_chars = (\n",
    "                sequence[start_pos:end_pos] + \"ATG\"\n",
    "            )  # The model was trained on upstream + start codon sequences, we don't want it to be out of distribution\n",
    "            sequences.append(current_chunk_chars)\n",
    "            start_positions.append(start_pos)\n",
    "        df = pd.DataFrame({\"seq\": sequences, \"start_pos\": start_positions})\n",
    "\n",
    "        tok_ds = preprocess_sequences(\n",
    "            df, self.tokenizer, self.proxy_species, \"seq\", num_proc=num_proc\n",
    "        )\n",
    "\n",
    "        for i in tqdm(range(math.ceil(len(tok_ds) / batch_size))):\n",
    "            batch = torch.tensor(\n",
    "                tok_ds[i * batch_size : (i + 1) * batch_size][\"input_ids\"]\n",
    "            )\n",
    "            idx = tok_ds[i * batch_size : (i + 1) * batch_size][\"start_pos\"]\n",
    "            idx = torch.tensor(idx, dtype=torch.long, device=self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                res = self.model(batch.to(self.device), output_hidden_states=True)[\n",
    "                    \"hidden_states\"\n",
    "                ]  # Layers * (B, L+6, H)\n",
    "                layer_embeddings = res[layers_from:]\n",
    "            mean_embedding = torch.mean(\n",
    "                torch.stack(layer_embeddings, dim=0), dim=0\n",
    "            )  # (B, L+6, H)\n",
    "            mean_embedding = mean_embedding[\n",
    "                :, 2:-4, :\n",
    "            ]  # species, begginigng and ATG end\n",
    "            assert mean_embedding.shape[0] == len(idx), (\n",
    "                f\"Mean embedding shape: {mean_embedding.shape}, idx length: {len(idx)}\"\n",
    "            )\n",
    "\n",
    "            B, L, H = mean_embedding.shape\n",
    "            position_offsets = torch.arange(L, device=idx.device)  # shape (L,)\n",
    "            positions = idx.unsqueeze(1) + position_offsets  # shape (B, L)\n",
    "\n",
    "            # flatten:\n",
    "            positions_flat = positions.reshape(-1)  # (B*L,)\n",
    "            values_flat = mean_embedding.reshape(-1, H)  # (B*L, H)\n",
    "            ones = torch.ones(B * L, device=idx.device)  # (B*L,)\n",
    "\n",
    "            # now scatter‚Äêadd:\n",
    "            sum_embeddings.index_add_(0, positions_flat, values_flat)\n",
    "            count_embeddings.index_add_(0, positions_flat, ones)\n",
    "        num_zeros = (count_embeddings == 0).sum().item()\n",
    "\n",
    "        assert num_zeros == 0, (\n",
    "            f\"Some nucleotides are not covered by any window ({num_zeros})\"\n",
    "        )\n",
    "        count_embeddings = count_embeddings.unsqueeze(1)\n",
    "        return sum_embeddings.cpu().to(torch.float32) / count_embeddings.cpu().to(\n",
    "            torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f424b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our new SpeciesLM embedder module\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from model.species_lm_embedder import SpeciesLMEmbedder\n",
    "\n",
    "# Initialize the embedder for gene expression prediction (upstream model)\n",
    "print(\"üß¨ Creating embedder for gene expression prediction (upstream model)...\")\n",
    "embedder = SpeciesLMEmbedder.for_gene_expression(\n",
    "    proxy_species=\"saccharomyces_cerevisiae\",\n",
    "    device=\"auto\",  # Will use CUDA if available, otherwise CPU\n",
    ")\n",
    "\n",
    "print(f\"SpeciesLM embedder initialized successfully!\")\n",
    "print(f\"Model device: {embedder.device}\")\n",
    "print(f\"Model revision: {embedder.model_revision}\")\n",
    "print(f\"Embedding dimension: {embedder.embedding_dim}\")\n",
    "print(f\"Species: {embedder.proxy_species}\")\n",
    "\n",
    "# Optionally, you can also create a downstream embedder for comparison\n",
    "print(\"\\nüß¨ You could also create an embedder for mRNA stability (downstream model):\")\n",
    "print(\"embedder_downstream = SpeciesLMEmbedder.for_mrna_stability()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c782362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define output directory\n",
    "output_directory = Path(\"../embeddings\")\n",
    "output_directory.mkdir(exist_ok=True)\n",
    "\n",
    "# Use our new embedder to process the FASTA file\n",
    "fasta_file_path = \"fasta_file.fsa\"\n",
    "\n",
    "print(\"Starting embedding process...\")\n",
    "print(f\"Input FASTA: {fasta_file_path}\")\n",
    "print(f\"Output directory: {output_directory}\")\n",
    "\n",
    "# Embed all sequences in the FASTA file using sliding windows for per-nucleotide embeddings\n",
    "output_files = embedder.embed_fasta_file(\n",
    "    fasta_path=fasta_file_path,\n",
    "    output_dir=str(output_directory),\n",
    "    mode=\"sliding\",  # Per-nucleotide embeddings\n",
    "    window_size=1000,  # 1kb windows\n",
    "    stride=50,  # 50bp stride for high resolution\n",
    "    layers_from=8,  # Use layers 8-12 for embeddings\n",
    "    batch_size=16,  # Batch size for memory efficiency\n",
    "    compress=True,  # Compress output files with gzip\n",
    ")\n",
    "\n",
    "print(f\"Successfully processed {len(output_files)} sequences!\")\n",
    "\n",
    "# Display results\n",
    "for seq_id, output_path in output_files.items():\n",
    "    print(f\"  {seq_id}: {output_path}\")\n",
    "\n",
    "    # Load and show stats for first sequence\n",
    "    if seq_id == list(output_files.keys())[0]:\n",
    "        embeddings = embedder.load_embeddings(output_path)\n",
    "        stats = embedder.get_embedding_stats(embeddings)\n",
    "        print(f\"    Shape: {stats['shape']}\")\n",
    "        print(f\"    Mean: {stats['mean']:.4f}\")\n",
    "        print(f\"    Std: {stats['std']:.4f}\")\n",
    "\n",
    "print(\"Embedding process completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede20e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load and analyze embeddings for downstream tasks\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load embeddings for the first chromosome\n",
    "first_seq_id = list(output_files.keys())[0]\n",
    "first_embedding_file = output_files[first_seq_id]\n",
    "\n",
    "print(f\"Loading embeddings for {first_seq_id}...\")\n",
    "embeddings = embedder.load_embeddings(first_embedding_file)\n",
    "\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "print(f\"This represents {embeddings.shape[0]} nucleotide positions\")\n",
    "print(f\"Each position has a {embeddings.shape[1]}-dimensional embedding\")\n",
    "\n",
    "# Example 1: Dimensionality reduction with PCA\n",
    "print(\"\\n1. Performing PCA for visualization...\")\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(\n",
    "    embeddings[::100]\n",
    ")  # Sample every 100th position for speed\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.6, s=1)\n",
    "plt.title(f\"PCA of DNA Embeddings for {first_seq_id}\")\n",
    "plt.xlabel(\"First Principal Component\")\n",
    "plt.ylabel(\"Second Principal Component\")\n",
    "plt.show()\n",
    "\n",
    "# Example 2: Find similar regions using clustering\n",
    "print(\"\\n2. Clustering similar genomic regions...\")\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings[::100])\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.scatter(range(len(clusters)), clusters, c=clusters, cmap=\"viridis\", alpha=0.7)\n",
    "plt.title(f\"Genomic Region Clusters for {first_seq_id}\")\n",
    "plt.xlabel(\"Genomic Position (sampled)\")\n",
    "plt.ylabel(\"Cluster\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Found {len(set(clusters))} distinct types of genomic regions\")\n",
    "\n",
    "# Example 3: Compute embedding statistics along the chromosome\n",
    "print(\"\\n3. Computing embedding statistics along chromosome...\")\n",
    "window_size = 1000\n",
    "step_size = 500\n",
    "\n",
    "embedding_norms = []\n",
    "positions = []\n",
    "\n",
    "for i in range(0, len(embeddings) - window_size, step_size):\n",
    "    window_embeddings = embeddings[i : i + window_size]\n",
    "    avg_norm = np.linalg.norm(window_embeddings, axis=1).mean()\n",
    "    embedding_norms.append(avg_norm)\n",
    "    positions.append(i + window_size // 2)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(positions, embedding_norms)\n",
    "plt.title(f\"Average Embedding Norm Along {first_seq_id}\")\n",
    "plt.xlabel(\"Genomic Position (bp)\")\n",
    "plt.ylabel(\"Average Embedding Norm\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Analysis complete! The embeddings are ready for downstream tasks.\")\n",
    "print(\"\\nPossible uses:\")\n",
    "print(\"- Predict gene expression levels\")\n",
    "print(\"- Identify regulatory elements\")\n",
    "print(\"- Classify genomic regions\")\n",
    "print(\"- Compare sequences across species\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
